{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import yaml\n",
    "from SalsaNext import SalsaNext\n",
    "sys.path.append('/ari/users/ibaskaya/projeler/kittisalsa/utils')\n",
    "model = SalsaNext(20,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "from glob import glob\n",
    "from scipy.ndimage import convolve\n",
    "import os\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.utils.data import DataLoader, DistributedSampler\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "DEBUG=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 20, 64, 2048])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = torch.randn((2,5,64,2048)) #Bura\n",
    "model(inp).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda  is used\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"model_state_path = '/kaggle/input/kittimidas/model_state_dict.pth'\\nstate_dict = torch.load(model_state_path)\\nmodel.load_state_dict(state_dict)\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "if torch.cuda.device_count()>1:\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "else:\n",
    "    model.to(device)\n",
    "model.to(device)\n",
    "print(device, ' is used')\n",
    "\n",
    "\"\"\"model_state_path = '/kaggle/input/kittimidas/model_state_dict.pth'\n",
    "state_dict = torch.load(model_state_path)\n",
    "model.load_state_dict(state_dict)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "from fastfill import FastFill\n",
    "from scale3d import RandomRescaleRangeImage\n",
    "from dskittiwaymo import SegmentationDataset\n",
    "\n",
    "ff = FastFill(tofill=0, indices=[0,1,2,3,4])\n",
    "transform_train = A.Compose([\n",
    "    #A.Resize(height=64, width=2048, interpolation=cv2.INTER_NEAREST, p=1),  # Resize\n",
    "    A.ShiftScaleRotate(shift_limit=0.5, scale_limit=0.0, rotate_limit=0, \n",
    "                       border_mode=cv2.BORDER_WRAP, interpolation=cv2.INTER_NEAREST,\n",
    "                       p=0.5),  \n",
    "    A.RandomCrop(height = 64, width = 2048, p=1),\n",
    "    #A.PadIfNeeded(min_height=64, min_width=2048, border_mode=0, value=0, mask_value=0),\n",
    "    A.HorizontalFlip(p=0.5),  # Horizontal flip with 20% probability\n",
    "    #A.CoarseDropout(max_holes=2, max_height=64, max_width=256, min_holes=1, min_height=1, min_width=1, fill_value=0, p=1),  # CoarseDropout instead of Cutout\n",
    "    ToTensorV2()  # Convert to PyTorch tensors\n",
    "], additional_targets={'mask': 'image'})\n",
    "transform_valid = A.Compose([\n",
    "    A.Resize(height=64, width=2048, interpolation=cv2.INTER_NEAREST, p=1),  # Resize\n",
    "    #A.RandomCrop(height = 64, width = 2048, p=1),\n",
    "    #A.PadIfNeeded(min_height=64, min_width=2048, border_mode=0, value=0, mask_value=0),\n",
    "    #A.HorizontalFlip(p=0.5),  # Horizontal flip with 20% probability\n",
    "    #A.CoarseDropout(max_holes=2, max_height=64, max_width=256, min_holes=1, min_height=1, min_width=1, fill_value=0, p=1),  # CoarseDropout instead of Cutout\n",
    "    ToTensorV2()  # Convert to PyTorch tensors\n",
    "], additional_targets={'mask': 'image'})\n",
    "#pretransform = RandomRescaleRangeImage(p=1)\n",
    "pretransform = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SegmentationDataset(root = '/ari/users/ibaskaya/projeler/kittisalsa/data/kitti', \n",
    "                                    split = 'training', transform=transform_train, \n",
    "                                    pretransform=pretransform, fastfill=ff, iswaymo=False, width=2048)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True, drop_last=True, num_workers=2)\n",
    "\n",
    "validation_dataset = SegmentationDataset(root = '/ari/users/ibaskaya/projeler/kittisalsa/data/kitti', \n",
    "                                    split = 'validation', transform=transform_valid, \n",
    "                                    pretransform=None, fastfill=ff, iswaymo=False, width=2048)\n",
    "validation_dataloader = torch.utils.data.DataLoader(validation_dataset, batch_size=8, shuffle=False, drop_last=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metric_miou import calculate_classwise_intersection_union,calculate_final_miou_from_batches, calculate_miou\n",
    "from printiou import print_miou_kitti as print_miou_results\n",
    "from lovasz import Lovasz_softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ari/users/ibaskaya/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:216: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n",
      " 52%|█████▏    | 1253/2391 [08:17<06:16,  3.03it/s] "
     ]
    }
   ],
   "source": [
    "num_classes = 20\n",
    "num_epochs = 42\n",
    "\n",
    "frequencies = [0.03150183342534689,\n",
    " 0.042607828674502385,\n",
    " 0.00016609538710764618,\n",
    " 0.00039838616015114444,\n",
    " 0.0021649398241338114,\n",
    " 0.0018070552978863615,\n",
    " 0.0003375832743104974,\n",
    " 0.00012711105887399155,\n",
    " 3.746106399997359e-05,\n",
    " 0.19879647126983288,\n",
    " 0.014717169549888214,\n",
    " 0.14392298360372,\n",
    " 0.0039048553037472045,\n",
    " 0.1326861944777486,\n",
    " 0.0723592229456223,\n",
    " 0.26681502148037506,\n",
    " 0.006035012012626033,\n",
    " 0.07814222006271769,\n",
    " 0.002855498193863172,\n",
    " 0.0006155958086189918]\n",
    "# Calculate the inverse frequency\n",
    "# Hyperparameters from the YAML file\n",
    "max_epochs = 42               # number of epochs\n",
    "learning_rate = 0.01           # initial learning rate for SGD\n",
    "warmup_epochs = 1              # number of warmup epochs\n",
    "momentum = 0.9                 # momentum for SGD\n",
    "lr_decay = 0.99                # learning rate decay factor per epoch\n",
    "weight_decay = 0.0001          # weight decay for optimizer\n",
    "batch_size = 8                # batch size\n",
    "epsilon_w = 0.001 \n",
    "inverse_frequencies = [1.0 / (f + epsilon_w) for f in frequencies]\n",
    "inverse_frequencies[0] = min(inverse_frequencies) / 10\n",
    "criterion_nll = nn.NLLLoss(weight=torch.tensor(inverse_frequencies).to(device))\n",
    "criterion_lovasz = Lovasz_softmax(ignore=0, from_logits=False)\n",
    "\n",
    "# Model, optimizer, and scheduler setup\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=lr_decay)\n",
    "\n",
    "# Warmup scheduler for initial epochs\n",
    "def warmup_lr_scheduler(optimizer, warmup_epochs, initial_lr):\n",
    "    def lr_lambda(epoch):\n",
    "        return epoch / warmup_epochs if epoch < warmup_epochs else 1\n",
    "    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
    "\n",
    "warmup_scheduler = warmup_lr_scheduler(optimizer, warmup_epochs, learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(max_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # Learning rate scheduling\n",
    "    if epoch < warmup_epochs:\n",
    "        warmup_scheduler.step()\n",
    "    else:\n",
    "        scheduler.step()\n",
    "\n",
    "    for i, (images, masks) in tqdm(enumerate(train_dataloader), total=len(train_dataloader)):\n",
    "        images, masks = images.to(torch.float32).to(device), masks.to(device)\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass and loss computation\n",
    "        outputs = model(images)\n",
    "        loss = criterion_nll(torch.log(outputs), masks) + criterion_lovasz(outputs, masks)\n",
    "\n",
    "        # Backpropagation and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{max_epochs}], Training Loss: {running_loss / len(train_dataloader):.4f}, LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    miou_total = 0.0\n",
    "    batch_results = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (images, masks) in enumerate(validation_dataloader):\n",
    "            images, masks = images.to(torch.float32).to(device), masks.to(device)\n",
    "\n",
    "            # Forward pass and predictions\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "            # mIoU calculation and class-wise IoU collection\n",
    "            miou = calculate_miou(preds, masks, num_classes, ignore_index=0)\n",
    "            cwiou = calculate_classwise_intersection_union(preds, masks)\n",
    "            batch_results.append(cwiou)\n",
    "\n",
    "            miou_total += miou\n",
    "\n",
    "    # Calculate and display mIoU metrics\n",
    "    classwise_iou, mean_iou, total_iou = calculate_final_miou_from_batches(batch_results)\n",
    "    print_miou_results(classwise_iou, mean_iou, total_iou)\n",
    "    avg_miou = miou_total / len(validation_dataloader)\n",
    "    print(f\"Epoch [{epoch+1}/{max_epochs}], Validation mIoU: {avg_miou:.4f}\")\n",
    "    print('################################################')\n",
    "\n",
    "    # Save model checkpoint\n",
    "    torch.save(model.state_dict(), f'model_state_dict_{epoch}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.cpu().state_dict(), 'model_state_dict.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "waymo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
